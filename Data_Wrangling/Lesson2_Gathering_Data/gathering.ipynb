{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading / Importing a flat file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'bestofrt' is a tsv file given. Donwload it to the working directory and load it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the Rotten Tomatoes bestofrt TSV file into a DataFrame\n",
    "df = pd.read_csv('bestofrt.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranking</th>\n",
       "      <th>critic_score</th>\n",
       "      <th>title</th>\n",
       "      <th>number_of_critic_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>The Wizard of Oz (1939)</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>Citizen Kane (1941)</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>The Third Man (1949)</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>99</td>\n",
       "      <td>Get Out (2017)</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>97</td>\n",
       "      <td>Mad Max: Fury Road (2015)</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ranking  critic_score                      title  number_of_critic_ratings\n",
       "0        1            99    The Wizard of Oz (1939)                       110\n",
       "1        2           100        Citizen Kane (1941)                        75\n",
       "2        3           100       The Third Man (1949)                        77\n",
       "3        4            99             Get Out (2017)                       282\n",
       "4        5            97  Mad Max: Fury Road (2015)                       370"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to see if the file was imported correctly\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two main ways to work with HTML files are:\n",
    "\n",
    "* Saving the HTML file to your computer (using the Requests library for example) library and reading that file into a BeautifulSoup constructor\n",
    "* Reading the HTML response content directly into a BeautifulSoup constructor (again using the Requests library for example)\n",
    "\n",
    "For this lesson, youâ€™re going to do neither of these. Download this zip file and extract the rt_html folder. I'm giving you these historical files because the ratings will change over time and there will be inconsistencies with the recorded lesson videos. Also, a web page's HTML is known to change over time. Scraping code can break easily when web redesigns occur, which makes scraping brittle and not recommended for projects with longevity. So just use these HTML files provided to you and pretend like you saved them yourself with one of the methods described below.\n",
    "\n",
    "The following cell has been commented because you don't need to execute the code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Code needed to download the data programmatically\\nimport requests\\nurl=\\'https://www.rottentomatoes.com/m/et_the_extraterrestrial\\'\\nresponse = requests.get(url)\\n\\n# Save HTML to file\\n\\nwith open(\"et_the_extraterrestrial.html\". mode=\"wb\") as file:\\n    file.write(response.content)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "METHOD 1\n",
    "# Code needed to download the data programmatically\n",
    "import requests\n",
    "url='https://www.rottentomatoes.com/m/et_the_extraterrestrial'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Save HTML to file\n",
    "\n",
    "with open(\"et_the_extraterrestrial.html\". mode=\"wb\") as file:\n",
    "    file.write(response.content)\n",
    "    \n",
    "# This is code needed to download one file - for more files put this code in a \n",
    "loop\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "METHOD 2\n",
    "\n",
    "#Repeat first step from above to download but don't save the file to HTML\n",
    "#Instead work with the 'response' content in memory\n",
    "\n",
    "# Work with the HTML in memory directly  using the BS HTML parser\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "soup=beautifulSoup(response.content)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now open the extracted files in Sublime Text and take a look at the HTML structure\n",
    "\n",
    "For the movie ET_the_extraterrestrial - there is audience score of 72% - to scrape this metric from the HTML file, \n",
    "From visual inspection we see that the 72% is inside the 'span' tag - we can find all instances of span tag in the text using Python's str.find function or a fancier tool called RegularExpressions - RegExr\n",
    "\n",
    "Beautiful Soup is an HTML parser written in Python - Let's use it to extract the title of the movie from the ET HTML page\n",
    "* Import the beautiful soup libary\n",
    "* Make the soup:\n",
    " Pass the html path to the file handle and pass the file handle to the beautiful   soup constructor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import beautiful soup library\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cdivy\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Users\\cdivy\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "with open('rt_html/et_the_extraterrestrial.html') as file:\n",
    "    soup = BeautifulSoup(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
