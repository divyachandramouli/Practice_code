Lesson 4
========================================================
After plotting histograms of people's guesses of perceived audience size, Moira wanted to see how it matched up with the actual audience size - turned to scatterplots


***

### Scatterplots and Perceived Audience Size
Usually scatterplot is the best to examine the relationship between 2 continuous variables

We see horizontal stripes at 50, 100, 200, etc. (y axis is perceived audience size - seems like a lot of people guessed the same numbers)
Points are big clusters at the bottom - people are guessing small numbers - in reality their size is 100, 200
***
```{r}
getwd()
```
LOAD DATA

```{r}
library(ggplot2)
pf <- read.csv('pseudo_facebook.tsv',sep='\t')
names(pf)
```


### Scatterplots
Notes:

```{r Scatterplots}
qplot(x=age, y=friend_count, data=pf)
```

***
The equivalent ggplot syntax for the scatterplot:

```{r}
ggplot(aes(x = age, y = friend_count), data = pf) +
  geom_point()
```

#### What are some things that you notice right away?
Response:
Younger users have a lot of friends - as you go right cluster reduces youngers users have 1000s of more friends than users over 30

Vertical bars - people of higher ages - even 100, could be lies or fake accounts of teenagers given the high friend counts

***
## Get an idea of age statistics

```{r}
summary(pf$age)
```
13 - 113 years is the range ; younger than 13 not permitted on facebook

### ggplot Syntax

Use an xlim layer to ggplot - exclude users above 90 - those ages could be fake data / lies

```{r ggplot Syntax}
ggplot(aes(x=age, y=friend_count), data=pf) + geom_point() + xlim(13,90)
```

***

### Overplotting
The area of the graph - bottom where points are stacked over each other - difficult to say how many points are in each region - overplotting
Set transparency of geom using alpha

```{r Overplotting}
ggplot(aes(x=age, y=friend_count), data=pf) + geom_point(alpha = 1/20) + xlim(13,90)
# Takes 20 points to be the equivalent of one black dot
```
Bulk of data is below 1000 threshold for friend count 
Swap out geom_point with jitter
Age is continuous but we only have integer value - perfectly lined up columns of age - intuitively wrong - add some noise to each age to see the relationship more clearly
```{r}
ggplot(aes(x=age, y=friend_count), data=pf) + geom_jitter(alpha = 1/20) + xlim(13,90)
# Takes 20 points to be the equivalent of one black dot
```
A more dispersed distribution

#### What do you notice in the plot?

The yound user friend counts are nearly as high as before
Bulk of young users have friend count below 1000
alpha is 1/20 - so it takes 20 points for a circle to appear completely dark
peak around 69 - faint - comparable to users in 25 or 26 age group
***

### Coord_trans()
### Transform the y axis using sqrt for a better visualization of the data - add a coord_trans layer to the geom_point plot

```{r Coord_trans()}
?coord_trans
```

#### Look up the documentation for coord_trans() and add a layer to the plot that transforms friend_count using the square root function. Create your plot!

```{r}
ggplot(aes(x=age, y=friend_count), data=pf) + geom_point(alpha = 1/20) + xlim(13,90) + coord_trans(y='sqrt')
```
We can see thresholds of friend count above which there are very few users 

We switched from jitter to point because if we want jitter we need to be careful and specify that the noise is for age and not friend count. Also, some users have a friend count of zero - adding noise to zero - we might end up with negative friend counts and those sqrt would be imaginary 

Add position_jitter and set a min height of 0 - advanced in terms of syntax - prevents from negative friend counts
Remember that jitter can add positive or negative noise to each point
```{r}
ggplot(aes(x=age, y=friend_count), data=pf) + geom_point(alpha = 1/20, position=position_jitter(h=0)) + xlim(13,90) + coord_trans(y='sqrt')
```
Adds jitter
prevents from negative friend counts
Remember that jitter can add positive or negative noise to each point
#### What do you notice?

***

### Alpha and Jitter

# Explore the relationship between friends initiated and age 

```{r Alpha and Jitter}
ggplot(aes(x=age,y=friendships_initiated),data=pf)+geom_point()+xlim(13,90)
```

```{r}
ggplot(aes(x=age,y=friendships_initiated),data=pf)+geom_point(alpha=1/10)+xlim(13,90)

```

Because of the discreteness in age, we jitter our points setting alpha as 10 points for one dark circle
```{r}
ggplot(aes(x=age,y=friendships_initiated),data=pf)+geom_jitter(alpha=1/10)+xlim(13,90)
```
Another way to produce the above plot with 'position'

```{r}
ggplot(aes(x=age,y=friendships_initiated),data=pf)+geom_point(alpha=1/10,position=position_jitter(h=0))+xlim(13,90) 
```
Since some friendships_initiated have very high values, let's take the coord_transformation (sqrt)

```{r}
ggplot(aes(x=age,y=friendships_initiated),data=pf)+geom_point(alpha=1/10,position=position_jitter(h=0))+xlim(13,90) + coord_trans(y='sqrt')
```

***

### Overplotting and Domain Knowledge
Makes more sense to think about audience size as a percentage of their friends - helps to reduce overplotting a bit

Perceived audeince (% friends) - y axis
Actual audience (%friends ) - x axis

Some people have 50  friends while some have 1000 - so percentage makes more sense



### Conditional Means

### find mean friend count by age

```{r Conditional Means}
install.packages('dplyr')
library(dplyr)
# group by age and compute statistics

age_groups <- group_by(pf,age)
pf.fc_by_age <- summarise(age_groups,
          friend_count_mean = mean(friend_count),
          friend_count_median = median(friend_count),
          n=n())

pf.fc_by_age <- arrange(pf.fc_by_age, age) #To sort the dataframe
head(pf.fc_by_age)
```

## Easier way to get the above table using %>% - chain command to do a chain of operations instead of storing intermediates in variables and passing them

```{r}
pf.fc_by_age <- pf %>%
  group_by(age) %>%
  summarise(friend_count_mean = mean(friend_count),
          friend_count_median = median(friend_count),
          n=n()) %>%
  arrange(age)
head(pf.fc_by_age,20)
```

## Create your plot of avg friend count vs age

```{r Conditional Means Plot}
ggplot(aes(x=age, y=friend_count_mean),data=pf.fc_by_age) + geom_line()
```
At higher ages, the friend count means are highly variable - all over the place
oddity at 69 - peak
For young users , they have high friend count means and between 30-60 friend counts hover just about a 100
***

### Overlaying Summaries with Raw Data
Quick exploration to display summaries over raw data


The original scatter plot of raw data is below:

```{r Overlaying Summaries with Raw Data}
ggplot(aes(x=age, y=friend_count), data=pf) + geom_point(alpha = 1/20, position=position_jitter(h=0), color ='orange') + xlim(13,90) + coord_trans(y='sqrt')
```
We want to overlay the summary graph over the raw data plot, so we changed the color
Add a geom line layer
fun.y takes any type of function that can be applied to the y values

```{r}
ggplot(aes(x=age, y=friend_count), data=pf) + geom_point(alpha = 1/20, position=position_jitter(h=0), color ='orange') + xlim(13,90) + coord_trans(y='sqrt')+
  geom_line(stat='summary', fun.y = mean)
```
Immediately reveals the increase in friend count for very young users and subsequent decrease
Can't see how dispersed the data is around the mean
Overlay another layer - quantiles 10 and 90% for better understanding of the data

```{r}
ggplot(aes(x=age, y=friend_count), data=pf) + geom_point(alpha = 1/20, position=position_jitter(h=0), color ='orange') + xlim(13, 90) + coord_trans(y='sqrt')+
  geom_line(stat='summary', fun.y = mean) +
  geom_line(stat='summary', fun.y = quantile, fun.args = list(probs= 0.1),linetype=2, color ='blue') + geom_line(stat='summary', fun.y = quantile, fun.args = list(probs= 0.9),linetype=2, color ='blue') + geom_line(stat='summary', fun.y = quantile, fun.args = list(probs= 0.5),color ='blue')
```
### Insights
Having more than 1000 friends is rare even for young people - 90% of users have less than 1000


To zoom in the code should use thecoord_cartesian(xlim = c(13, 90)) layer rather than xlim(13, 90) layer. Remove coord_trans 
Let's look at users between 13 and 70, and since most users have less than 1000, we'll limit y as well

```{r}
ggplot(aes(x=age, y=friend_count), data=pf) + geom_point(alpha = 1/20, position=position_jitter(h=0), color ='orange') + coord_cartesian(xlim = c(13, 70), ylim=c(0,1000)) + 
  geom_line(stat='summary', fun.y = mean) +
  geom_line(stat='summary', fun.y = quantile, fun.args = list(probs= 0.1),linetype=2, color ='blue') + geom_line(stat='summary', fun.y = quantile, fun.args = list(probs= 0.9),linetype=2, color ='blue') + geom_line(stat='summary', fun.y = quantile, fun.args = list(probs= 0.5),color ='blue')
  
```

#### What are some of your observations of the plot?
For 35 - 60 year olds the friend count falls below 250

***

### Moira: Histogram Summary and Scatterplot
Aligning the histogram summary and scatterplot

Actual % of friends - perceived 5 of friend = by how much the audience underestimated the size

A histogram of this data shows how many people fell in each percent of underestimation 
0% means exactly estimated
negative percent - over estimation
Positive percent : Underestimation

Notes:

***

### Correlation
try to summarize the strength of relationship between age and friend count using a correlation coefficient
Use the Pearson product moment correlation (r) to measure the linear relationship

```{r Correlation}
?cor.test
```

Look up the documentation for the cor.test function.

What's the correlation between age and friend count? Round to three decimal places.

```{r}
cor.test(pf$age, pf$friend_count, method= "pearson")
```

Response:
We get a corr coeff of -.0274 - indicates no meaningful relationship between the two 
A good rule of thumb is that a coeff
> 0.3 or <-0.3 is meaningful but small
around 0.5 is moderate
>0.7 is large

the relationship is not linear - not monotonic either inc or dec


Another way to do this

with allows us to run the R function in an environment constructed from the data

```{r}
with(pf, cor.test(age,friend_count, method = 'pearson'))
```

### Correlation on Subsets
We know that the relationship is not meaningful, not monotonic
Maybe we don't want to include the older ages in the plot - likely to be incorrect
users ostensibly of age 70 or less (apparently or purportedly, but maybe not actually)

```{r Correlation on Subsets}
with(subset(pf, pf$age<=70), cor.test(age, friend_count))
```
A different story - indicates a negative relationship
Friend count decreases as age increases
But one variable doesn't cause the other - growing old doesn't mean they'll have fewer internet friends
Use inferential statistics on data from experimental research rather than descriptive statistics to address causality
***

### Correlation Methods
Measures of monotonic relationships:
Rank correlation - like spearman 

```{r}
with(subset(pf, age<=70), cor.test(age, friend_count, method = 'spearman'))
```
here we have a different test statistic called rho , it has a different value

http://www.statisticssolutions.com/correlation-pearson-kendall-spearman/

Single number coefficients are useful but not great substitutes to studying scatter plots and computing conditional summaries - richer understanding from plots
***

## Create Scatterplots
Look at number of likes received from desktop version of the sites and compare it with the total number of likes received

```{r}
ggplot( aes (www_likes_received, likes_received), data=pf)+geom_point()
```

***

### Strong Correlations
the plot has funky outliers and bulk of data is at the bottom
To determine good axis limits let's look at 95th percentile



```{r Strong Correlations}
ggplot( aes (www_likes_received, likes_received), data=pf)+geom_point()+
  xlim(0,quantile(pf$www_likes_received,0.95)) +
  ylim(0,quantile(pf$likes_received,0.95))
```
this in effect zooms in on the lower portion of the graph 
Get a line of best fit through these points - slope of this line is the correlation
Add a geom_smooth layer, set the method to a linear model

```{r}
ggplot( aes (www_likes_received, likes_received), data=pf)+geom_point()+
  xlim(0,quantile(pf$www_likes_received,0.95)) +
  ylim(0,quantile(pf$likes_received,0.95))+
  geom_smooth (method= 'lm', color= 'red')
```



###What's the correlation betwen the two variables? Include the top 5% of values for the variable in the calculation and round to 3 decimal places.

```{r Correlation Calcuation}
cor.test(pf$www_likes_received, pf$likes_received)
```
Using the whole data, without ignoring outliers
This gives a strong positive correlation - as the number of desktop likes increases, total likes increase -  In reality most variables are not correlated that closely
The correlation we found is an artifact of the nature of our variables - one of them is a superset of the other

The correlation coefficient is invariant under a linear transformation of either X or Y, and the slope of the regression line when both X and Y have been transformed to z-scores is the correlation coefficient.

It's important to note that we may not always be interested in the bulk of the data. Sometimes, the outliers ARE of interest, and it's important that we understand their values and why they appear in the data set.

### Moira on Correlation
Strong correlations are not always a good thing
How many status updates posted correlated with number of times they logged in or how many friends or how many photos
They all measure engagement - all related 
One of the assumptions of regression - the variables are independent of each other - it'll be difficult to tell which ones are actually driving the phenomenon
Important to measure correlation - you'll know which ones you shouldn't throw in together and which ones to keep
https://en.wikipedia.org/wiki/Linear_regression#Assumptions

***

### More Caution with Correlation
Correlation coefficients can be deceptive - plotting the data is the best way to understand key insights


```{r More Caution With Correlation}
#install.packages('alr3')
library(alr3)
data(Mitchell)
?Mitchell
names(Mitchell)
```
We'll see how correlation can be deceptive

###Create your plot!

```{r Temp vs Month}
ggplot( aes(Month,Temp), data=Mitchell)+geom_point()
```

Argument matching (when not providing them by name) in R is a bit complex.

First, arguments (or parameters) can be matched by name. If a parameter matches exactly, it is "removed" from the argument list and the remaining unnamed arguments are matched in the order that they are listed in the function definition.

R does the following to match arguments... 

checks for exact match of named argument
checks for a partial match of the argument
checks for a positional match
If R does not find a match for a parameter, it typically throws an "unused" parameter error.

Type str(functionName) to find the order of the parameters and learn more about the parameters of an R function. 

***

### Noisy Scatterplots
a. Take a guess for the correlation coefficient for the scatterplot.
0, looks like no correlation

b. What is the actual correlation of the two variables?
(Round to the thousandths place)

```{r Noisy Scatterplots}
cor.test(Mitchell$Month,Mitchell$Temp)
```
The actual value looks like a large correlation in the data
***

### Making Sense of Data
###Write code to make the x axis more sensible - months - to break up the x axis every 12 months - what layer would you add?

```{r}
range(Mitchell$Month)
```


```{r Making Sense of Data}
ggplot( aes(Month,Temp), data=Mitchell)+geom_point()+scale_x_continuous(breaks=seq(0,203,12))
```

***

### A New Perspective

What do you notice?
### Take the plot and strecth it out - make the horizontal axis longer in R - what do you notice?
You get a cyclical pattern like a sin graph
```{r}
ggplot( aes(Month,Temp), data=Mitchell)+geom_line()+scale_x_continuous(breaks=seq(0,203,12))
```
This makes sense - seasons every 12 months and there should be fluctuations in temperature every 12 months - important put your data in context and get perspective

proportion and scale of the data is very important - nature of the data should suggest the shape of the graphic , Otherwise ypou should tend to have a graphic that is 50% wider than it is tall - stretch out the graph for perspective!!


###Watch the solution video and check out the Instructor Notes!
Notes:
You could also get perspective on this data by overlaying each year's data on top of each other, giving a clear, generally sinusoidal graph. You can do this by using the R's modulus operator %% in your code. Try running the code below!

ggplot(aes(x=(Month%%12),y=Temp), data=Mitchell)+
  geom_point()
  
  There are other measures of associations that can detect this. The dcor.ttest() function in the energy package implements a non-parametric test of the independence of two variables. While the Mitchell soil dataset is too coarse to identify a significant dependency between "Month" and "Temp", we can see the difference between dcor.ttest and cor.test through other examples, like the following:

x <- seq(0, 4*pi, pi/20)
y <- cos(x)
qplot(x = x, y = y)
dcor.ttest(x, y)
***

### Understanding Noise: Age to Age Months
Let's return to the scatterplot that summarised the relationship between age and mean friend count

```{r Understanding Noise: Age to Age Months}
ggplot(aes(x=age, y=friend_count_mean),data=pf.fc_by_age) + geom_line()
```
The line has a lot of noise - rises and falls over each age
```{r}
pf.fc_by_age[17:19,]
```
The mean friend count for age 30 is lower than 31 - some year discontinuities might make sense like the spike at 69 but others are more likely to be noise around the true smoother relationship between age and friend count
We just have a sample for analysis and the estimated mean is the true mean + some noise
The noise would be worse if we chose finer bins for age - for, eg measure conditional mean for each age measured in months instead of years


***
### Create an age with months variable and save into the dataframe
# Create a new variable, 'age_with_months', in the 'pf' data frame.
# Be sure to save the variable in the data frame rather than creating
# a separate, stand-alone variable. You will need to use the variables
# 'age' and 'dob_month' to create the variable 'age_with_months'.

# Assume the reference date for calculating age is December 31, 2013.

# This programming assignment WILL BE automatically graded. For
# this exercise, you need only create the 'age_with_months' variable;
# no further processing of the data frame is necessary.

```{r}
names(pf)
pf$age_with_months <- pf$age + (12-pf$dob_month)/12
head(pf)
```


### Age with Months Means

```{r Age with Months Means}
pf.fc_by_age_months <- pf %>%
      group_by(age_with_months) %>%
  summarise(friend_count_mean = mean(friend_count),
          friend_count_median = median(as.numeric(friend_count)),
          n=n()) %>%
  arrange(age_with_months)

head(pf.fc_by_age_months,20)
```

Programming Assignment
```{r Programming Assignment}
  
```

***

### Noise in Conditional Means

```{r Noise in Conditional Means}
ggplot(aes( x= age_with_months, y= friend_count_mean),data=subset(pf.fc_by_age_months,age_with_months < 71)) + geom_line()
  
```

***

### Smoothing Conditional Means
Compare the age_with_months plot with plot for just age also subset to < 71
```{r Smoothing Conditional Means}
ggplot( aes(x=age, y=friend_count_mean),data=subset(pf.fc_by_age, age < 71)) + geom_line()
```
```{r}
p1 <- ggplot(aes( x= age_with_months, y= friend_count_mean),data=subset(pf.fc_by_age_months,age_with_months < 71)) + geom_line()

p2 <- ggplot( aes(x=age, y=friend_count_mean),data=subset(pf.fc_by_age, age < 71)) + geom_line()
library (gridExtra)
grid.arrange(p1,p2,ncol=1)
```

By dec size of bins and inc no of bins - less data to estimate each conditional mean
Noise is worse when you have finer bins choices

## Create this plot - Inc size of bins and say, avg friend_counts by age being a multiple of 5 - lot of points get lumped into one number
```{r}
p3 <- ggplot( aes(x= round (age/5)*5 , y=friend_count_mean),data=subset(pf.fc_by_age, age < 71)) + geom_line(stat='summary',fun.y = mean)

grid.arrange(p1,p2,p3)

```
3rd plot - Less data points -wider bins - estimate mean more precisely but potentially miss major features of the age vs friend_count relationship

Exampleof Bias-variance trade-off - similar to trade-off while choosing bin width i  histograms
One way is to use a flexible statistical model to smooth the estimates
of conditional means
ggplot helps to smooth - geom_smooth - fit along the function

Adding geom_smooth with defaults
```{r}
p1 <- ggplot(aes( x= age_with_months, y= friend_count_mean),data=subset(pf.fc_by_age_months,age_with_months < 71)) + geom_line()+geom_smooth()

p2 <- ggplot( aes(x=age, y=friend_count_mean),data=subset(pf.fc_by_age, age < 71)) + geom_line()+geom_smooth()

p3 <- ggplot( aes(x= round (age/5)*5 , y=friend_count_mean),data=subset(pf.fc_by_age, age < 71)) + geom_line(stat='summary',fun.y = mean)

grid.arrange(p1,p2,p3)

```

While the smoother captures some of the features of relationship it doesn't draw attention to the non motonic relationship at lower ages - really misses discontinuity at 69
 
This indicates that using models like LOESS or smoothing splines can be useful, but like any model it can be subject to systematic errors when the true process generating our data isn't so consistent with the model itself
Here the models are based on the idea that the true function is smooth but we really know that there is some discontinuity in the relationship

***

### Which Plot to Choose?

You don't have to choose - can have multiple visualizations and summaries from the same data gleaning different insightsfrom each
As we iteratively refine plots of the same data, later plots are not always better, sometimes they just reveal different things about the same data
Choose visualizations that best communicate the main findings of your work

***

### Analyzing Two Variables
-Scatter plots - main tool to explore relationship between 2 variables - augmented the plots with conditional summaries like means
- Benefits and limitations of correlations - can affect decisions as to which variables to include in the final model
- Make sense of data by adjusting visualization - seasonal data 
- Use jitter and transparency to reduce overplotting

http://dept.stat.lsa.umich.edu/~kshedden/Courses/Stat401/Notes/401-bivariate-slides.pdf

***

Click **KnitHTML** to see all of your hard work and to have an html
page of this lesson, your answers, and your notes!

