Diamonds - predictive model
========================================================
- Use EDA to develop a quantitative understanding of the diamond market. 
- Build a predictive model of diamonds to figure out whether a given diamond is a good deal or a rip-off
- Exploring this can help understand what goes into the price of a diamond
- Diamonds gave rise to the mining industry in South Africa - world's most advanced economy in the region

### Use a linear regression model to predict diamond price using other variables in the diamonds dataset.

### Scatterplot Review

Let's start by examining two variables in the data set. The scatterplot is a powerful tool to help you understand the relationship between two continuous variables.

 We can quickly see if the relationship is linear or not. In this case, we can use a variety of diamond characteristics to help us figure out whether the price advertised for any given diamond is reasonable or a rip-off.

Let's consider the price of a diamond and it's carat weight. Create a scatterplot of price (y) vs carat weight (x).

#### Limit the x-axis and y-axis to omit the top 1% of values.

```{r Scatterplot Review}
install.packages("ggplot2")
library(ggplot2)
data("diamonds")
names(diamonds)
```


### Range of price

```{r}
summary(diamonds$price)
```

### Trim the top 1% off of the x axis and y axis

```{r}
ggplot(aes(x= carat, y= price), data = diamonds)+ geom_point(fill=I('#F79420'), color=I('black'),shape=21)+xlim(0, quantile(diamonds$carat,0.99))+ylim(0,quantile(diamonds$price, 0.99))
```


### Solution using qplot
```{r}
qplot(data= diamonds, x=carat, y=price, xlim=c(0,quantile(diamonds$carat,0.99)), ylim=c(0,quantile(diamonds$price,0.99)))+geom_point(fill = I('#F79420'), color=I('black'), shape=21)
```

### Solution using ggplot

```{r}
ggplot(aes(x=carat, y=price), data=diamonds)+scale_x_continuous(lim=c(0,quantile(diamonds$carat,0.99)))+scale_y_continuous(lim=c(0,quantile(diamonds$price,0.99)))+geom_point(fill = I('#F79420'), color=I('black'), shape=21)
```

***

### Price and Carat Relationship
- Non linear relationship - exp or something else
- Dispersion/varaiance of the relationship inc as carat inc
- Can add a linear trendline using the stat_smooth with method = 'lm'

```{r}
ggplot(aes(x=carat, y=price), data=diamonds)+scale_x_continuous(lim=c(0,quantile(diamonds$carat,0.99)))+scale_y_continuous(lim=c(0,quantile(diamonds$price,0.99)))+geom_point(color='#F79420', alpha=1/4)+ stat_smooth(method='lm')
```
The linear trendline does not go through the center of the data in some key places - misses curving in the center of the plot and should slope up more towards the end

If we try to make predictions using this we might be off at some places inside and outside of the existing data that we have displayed 


***

### Frances Gerety
#### The diamonds dataset
- Ships with ggplot2
- Contains prices and specs for >50000 diamonds collected in 2008 from diamondsc.info
- Can't just plug in a model no. and look up the price - diamonds are unique

DeBeers Cartel (1888) - Formed to control the global price of diamonds  - 'A diamond is forever'

***

### The Rise of Diamonds
Massive persuasion - diamonds became a status symbol and indispensable in engagement rings 
***

### ggpairs Function
#### First thing you might consider doing is plotting key variables against each other using the ggpairs function 
- You may want to sample first - otherwise the function may take a long time to render the plots
- Also, if there are more than 10 columns there may be too many plotting windows, so subset on columns first if that's the case

Packages

GGally - for this plot
scales - variety of  things
Memisc - summarize the regression
lattice - few other things
MASS - various functions
car - recode variables
reshape - to reshape and wrangle data
dplyr- create interesting summaries and transformations of your data

```{r ggpairs Function}
# install these if necessary
install.packages('GGally')
install.packages('scales')
install.packages('memisc')
install.packages('lattice')
install.packages('MASS')
install.packages('car')
install.packages('reshape')
install.packages('dplyr')
install.packages("ggplot2")
install.packages('RColorBrewer')

```

```{r}
# load the ggplot graphics package and the others
library(ggplot2)
library(GGally)
library(scales)
library(memisc)
library(dplyr)

```


```{r}
# sample 10,000 diamonds from the data set
set.seed(20022012)
# sample 10000 row number in the range 1-length(data) , all columns
diamond_samp <- diamonds[sample(1:length(diamonds$price), 10000), ]
ggpairs(diamond_samp, axisLabels = 'internal',
        lower = list(continuous = wrap("points", shape = I('.'))), 
        upper = list(combo = wrap("box", outlier.shape = I('.'))))
```

### What are some things you notice in the ggpairs output?

Lower triangle 
- Grouped histograms for qualitative vs qualitative pairs using y as the grouping factor
- Scatterplots for quantitative vs quantitative pairs

Upper triangle
- Grouped histograms for qualitative vs qualitative pairs - this time using x instead of y as the grouping factor
- box plots for qualitative vs quantitative pairs 
- Correlation for quantitative vs quantitative pairs

The "params" argument to the ggpairs function are there to change the shape of the plotted points in the plot matrix, to make them easier to see. GGally 1.0 changes the syntax of these plotting parameters to no longer be part of a params argument, and instead can be specified as follows:

ggpairs(diamond_samp,
  lower = list(continuous = wrap("points", shape = I('.'))),
  upper = list(combo = wrap("box", outlier.shape = I('.'))))
You can click on the packages tab in RStudio to determine which packages have been installed.

You may receive a message when installing the new packages. If so, click cancel, clear your workspace, and try installing the packages again.

In this video, Solomon works with the plyr package. We worked with the dplyr package to manipulate data frames and to create new ones throughout the course. dplyr is the latest version of plyr that is specifically for working with data frames.

Similarly, we worked with the reshape2 package, which is the newest version of the reshape package.

When you duplicate the plot matrix on your local machine, you may want to add a axisLabels = 'internal' argument to your ggpairs function call to have the variable names on the diagonal of the matrix rather than on the outside.

### Look closely at the relationships that correspond to price - what do you notice?

Critical factor driving price is the size/carat weight of the diamonds

Relationship between price and carat is nonlinear. What might explain this pattern?

On the supply side, maybe larger continuous chunks of diamonds without flaws are harder to find than smaller ones - might help explain exponential looking curve

Weight = f (volume) = f(x*y*z)

We might be especially interested in the cube root of carat weight
Leveraging substantive knowledge about your data like this can lead to fruitful transformations

***
### look at price vs carat plot

```{r}
ggplot(aes(x=carat, y=price), data=diamonds)+scale_x_continuous(lim=c(0,quantile(diamonds$carat,0.99)))+scale_y_continuous(lim=c(0,quantile(diamonds$price,0.99)))+geom_point(fill = I('#F79420'), color=I('black'), shape=21)
```

### The Demand of Diamonds

On the demand side , customers in the market for a less expensive smaller diamond are probably more sensitive to price than more well to do customers.
Those buying less than 1 carat would almost surely never buy a diamond if not for the social norm of using a diamond while proposing
Fewer customers can afford a bigger diamond - more than 1 carat - we shouldn't expect the market for bigger diamonds to be as competitive as the one for smaller diamonds 
So it makes sense that the prce and variance increase with carat size

Often the distribution of any monetary variable like dollars will be highly skewed and varyover orders of magnitude - this can be due to path dependence ( rich getting richer) or  multiplicative processes like year on year inflation or a combination of both - so a good idea to look into compressing any such variable by putting it on a log scale

More tips on when to use log transformation

https://www.r-statistics.com/2013/05/log-transformations-for-skewed-and-wide-distributions-from-practical-data-science-with-r/

### Let's examine the distribution of price again  - generate two price histograms

### Create two histograms of the price variable and place them side by side on one output image. We've put some code below to get you started. The first plot should be a histogram of price and the second plot should transform the price variable using log10. Set appropriate bin widths for each plot. ggtitle() will add a title to each histogram.



```{r The Demand of Diamonds}

library(gridExtra)
plot1 <- qplot(x=price, data= diamonds, binwidth=100,fill=I('orange')) + 
  ggtitle('Price')

plot2 <- qplot(x=price, data=diamonds,binwidth=0.01,fill=I('blue')) + scale_x_log10()+
  ggtitle('Price (log10)')

grid.arrange(plot1,plot2)
```

***

### Connecting Demand and Price Distributions
When looking at these plots what do you notice? Specifically about the wopeaks in the transformed plot and how it relates to teh demand for diamonds

From the raw histogram , we see that diamond orices are heavily skewed. When we put the prices on a log10  scale, they seem more well behaved - closer to the bell curve of a normal distribution 
We can even seea bit of evidence of bimodality in the log10 scale which is consistent with our two class rich buyer, poor buyer speculation about the nature of diamond customers

We saw a sneak peek of this wehn we looked at log10 price by cut
***

### Scatterplot Transformation

### Replot the data with price on log10 scale - price by cut histogram

```{r Scatterplot Transformation}
qplot(x=carat, y=price, data=diamonds)+scale_y_log10()+ggtitle('price(log10) by carat')
```

On the log scale prices look less dispersed on the high  end of carat size and price
We can actually do better 

Let's try to use the cuberoot variable in light of our speculation about the flaws being exponentially more likely in diamonds of more volume

### Create a new function to transform the carat variable
inverse is to undo the operation - needed to display the plot correctly

### Writing your own function in R

https://www.youtube.com/watch?v=Z1wB1rHAYzQ&list=PLOU2XLYxmsIK9qQfztXeybpHvru-TrqAP
```{r cuberoot transformation}
cuberoot_trans = function() trans_new ('cuberoot', transform = function(x) x^(1/3),
                                      inverse = function(x) x^3)
```

#### Use the cuberoot_trans function for x axis - carat and log10 transformation for y axis - price
```{r Use cuberoot_trans}
ggplot(aes(carat, price), data = diamonds) + 
  geom_point() + 
  scale_x_continuous(trans = cuberoot_trans(), limits = c(0.2, 3),
                     breaks = c(0.2, 0.5, 1, 2, 3)) + 
  scale_y_continuous(trans = log10_trans(), limits = c(350, 15000),
                     breaks = c(350, 1000, 5000, 10000, 15000)) +
  ggtitle('Price (log10) by Cube-Root of Carat')
```
Things look almost linear now after the two transformation

We can now move forward and try modelling our data using just a linear model
***

### Overplotting Revisited
Until now we haven't done anything about overplotting - when multiple points take on the same value - often due to rounding 
Let's look at this by running the table command on carat and price, then sort that so that highest values appear first ( look at top 6)



```{r Sort and Head Tables}
head(sort(table(diamonds$carat), decreasing = T ))
head(sort(table(diamonds$price), decreasing = T))
```
First line is the carat/price
Second line is the count of each of these values

We see that the counts are high - substantial overplotting - obscures the density and sparsity of our data - really key points 
Deal with this by making your points smaller - jittering, adding transparency (in ggplot - alpha parameter)

```{r Overplotting Revisited}
library(ggplot2)
ggplot (aes(carat, price), data = diamonds) + 
  geom_point(alpha=1/2, position='jitter', size=0.75) + 
  scale_x_continuous(trans = cuberoot_trans(), limits = c(0.2, 3),
                     breaks = c(0.2, 0.5, 1, 2, 3)) + 
  scale_y_continuous(trans = log10_trans(), limits = c(350, 15000),
                     breaks = c(350, 1000, 5000, 10000, 15000)) +
  ggtitle('Price (log10) by Cube-Root of Carat')
```
A better sense of how dense / sparse our data is at key places is given by this plot after dealing with overplotting

***

### Other Qualitative Factors
We can see an almost linear relationship between carat and price after doing some transformations
But surely there are other factors that influence the price of diamonds - You can notice that clarity seems to factor into price
Ofcourse many consumers are looking for a diamond of certain min size - so clarity is not as strong a factor as carat weight
Most people need a jeweler to tell the difference in clarity - hard to tell by just looking
According to blue nile the cut of a diamond has a much more consequential impact on the firy quality of diamonds. On clarity the website says many of these imperfections are microscopic and do not affect the diamond's beauty in any discernable way



***

### Price vs. Carat and Clarity
Let's see if clarity, cut and color can explain some of the variance in price when we visualize it on our plot using color

Alter the code below.
```{r Price vs. Carat and Clarity}
# Adjust the code below to color the points by clarity.

# A layer called scale_color_brewer() has 
# been added to adjust the legend and
# provide custom colors.

# See if you can figure out what it does.
# Links to resources are in the Instructor Notes.

# You will need to install the package RColorBrewer
# in R to get the same colors and color palettes.
# install and load the RColorBrewer package
install.packages('RColorBrewer',dependencies = TRUE)
library(RColorBrewer)

library(ggplot2)
# This code examines price by carat
# We add the color parameter in the aesthetic wrapper
ggplot(aes(x = carat, y = price,  color= clarity), data = diamonds) + 
  geom_point(alpha = 0.5, size = 1, position = 'jitter') +
  scale_color_brewer(type = 'div',
    guide = guide_legend(title = 'Clarity', reverse = T,
    override.aes = list(alpha = 1, size = 2))) +  
  scale_x_continuous(trans = cuberoot_trans(), limits = c(0.2, 3),
    breaks = c(0.2, 0.5, 1, 2, 3)) + 
  scale_y_continuous(trans = log10_trans(), limits = c(350, 15000),
    breaks = c(350, 1000, 5000, 10000, 15000)) +
  ggtitle('Price (log10) by Cube-Root of Carat and Clarity')
```

***

### Clarity and Price
### Based on the plot do you think clarity explains some of the change in price? Why?
Clarity does explain an awful lot of the remaining variance in price after adding color to the plot
Holding the carat weight constant, we're looking at one part of the plot. We see the diamonds with lower clarity are almost always cheaper than diamonds with better clarity
***

### Price vs. Carat and Cut

### Alter the code below to color the points by cut. Change the titles
```{r Price vs. Carat and Cut}
ggplot(aes(x = carat, y = price, color = cut), data = diamonds) + 
  geom_point(alpha = 0.5, size = 1, position = 'jitter') +
  scale_color_brewer(type = 'div',
                     guide = guide_legend(title = 'Cut', reverse = T,
                                          override.aes = list(alpha = 1, size = 2))) +  
  scale_x_continuous(trans = cuberoot_trans(), limits = c(0.2, 3),
                     breaks = c(0.2, 0.5, 1, 2, 3)) + 
  scale_y_continuous(trans = log10_trans(), limits = c(350, 15000),
                     breaks = c(350, 1000, 5000, 10000, 15000)) +
  ggtitle('Price (log10) by Cube-Root of Carat and Cut')
```

***

### Cut and Price
### Based on the plot do you think cut accounts for some of the variance in price? Why?

We don't see too much variation on cut the way we saw with clarity 
Most of the diamonds in the data are ideal cut anyway. So we lost the color pattern that we saw before

***

### Price vs. Carat and Color

### Alter the code below to color the plot by diamond color
### Remove reverse = T on the guide_legend? It's a small detail that reminds us that D is the best color and J is worse for rating diamond colors. We want the best color at the top of the list in the legend
```{r Price vs. Carat and Color}
ggplot(aes(x = carat, y = price, color = color), data = diamonds) + 
  geom_point(alpha = 0.5, size = 1, position = 'jitter') +
  scale_color_brewer(type = 'div',
                     guide = guide_legend(title = 'Color',
                                          override.aes = list(alpha = 1, size = 2))) +  
  scale_x_continuous(trans = cuberoot_trans(), limits = c(0.2, 3),
                     breaks = c(0.2, 0.5, 1, 2, 3)) + 
  scale_y_continuous(trans = log10_trans(), limits = c(350, 15000),
                     breaks = c(350, 1000, 5000, 10000, 15000)) +
  ggtitle('Price (log10) by Cube-Root of Carat and Color')
```

***

### Color and Price
### Based on the plot do you think that color of a diamond influences price? Why?
Color does seem to explain some of the variance in price like clarity does. Blue nile however states that the difference between all color grades from D to J are basically not noticeable to the naked eye. Yet we do see the color difference in the price tag
***

### Linear Models in R
In r we create models using the lm() function

Formula in the form of  lm(Y ~ X) where Y is the outcome variable and X is the explanatory variable
Which of the formulas would we inside the lm() function?

lm(log10(price) ~ carat^(1/3))

Price is the outcome and carat is the predictor variable. We used our domain knowledge of diamonds and carat weight to take the cube root of carat weight (volume).

We applied the log transformation to our long tailed dollar variable and we speculated that the flawless diamond should become exponentially rare as diamond volume increases - so we should be interested in the cube root of carat weight 



***

### Building the Linear Model
The I wrapper is used around each of the variables -I stands for as is - tells R to use the expression inside the I function to transform a variable before using it in the regression - this is instead of instructing R to interpret these symbols as part of the formula to construct the design matrix for regression
You can update the prev model to add the carat variable in the regression using m2. The real functional relationship is surely not as simple as the cube root of carat so we add a  simple linear function of carat in our model predicting price. We can continue to make more complex models by adding more variables. We add cut though we don't expect it to have much influence on the price
next we add color to our fourth and clarity to fifth 


```{r Building the Linear Model}
#If you are running this code on your local computer, you may need to modify the last line to state: mtable(m1, m2, m3, m4, m5, sdigits = 3). This will ensure that the output at the end of the table shows three significant digits like shown in the video.
m1 <- lm(I(log(price)) ~ I(carat^(1/3)), data = diamonds)
m2 <- update(m1, ~ . + carat)
m3 <- update(m2, ~ . + cut)
m4 <- update(m3, ~ . + color)
m5 <- update(m4, ~ . + clarity)
mtable(m1, m2, m3, m4, m5)
```
We see some nice R squared values.
We are accounting for almost all the variance in price using the 4 Cs - Carat, Clarity, Color and Cut
if we want to know whether the price for a diamond is reasonable we might now use this model. 

Notice how adding cut to our model does not help explain much of the variance
in the price of diamonds. This fits with out exploration earlier.

***

### Model Problems
Can write the model equation as:

log(price) = 0.415 + 9.144 * (carat)^(1/3) -1.093*carat + (... * cut + ...* color + ...* clarity) + Epsilon(error term) 

### What could be some problems when using this model ? What else should we think about while using this model?
- To start our data is from 2008. So not only do we need to account for inflation, but the diamond market is quite different now than it was. Infact when you fit models to this data and predict price for diamond that you find off a market you get predictions that were way too low. 

- After some digging it was found that global diamonds were poor. It turns out that prices plummeted in 2008 due to the global financial crisis. SInce then prices atleast for wholesale polished diamonds have grown at atleast 6% per year compound annual rate 

- Diamond market in China heating up - the rapidly growing #couples in China buying diamond engagement rings might also explain the increase. Visit below links to learn more

After looking at data on price scope I realized diamond prices grew unevenly across different carat sizes since 2008 meaning that the initial model couldn't simply be adjusted by inflation

***

### A Bigger, Better Data Set
A python script to put together the current diamond price data similar to the original diamonds dataset from diamondsc.info - about ten times the size of 2008 dataset - contains diamonds from all over the world certified by an array of authorities besides just the Gemological Institute of America or  the GIA

You can read in this dataset (more than 500,000 cases) , but make sure you have installed Rcurl and bitops libraries 

```{r A Bigger, Better Data Set}
install.packages('bitops')
install.packages('RCurl')
library('bitops')
library('RCurl')
# To directly load new dataset from web
#diamondsurl = getBinaryURL("https://raw.github.com/solomonm/diamonds-data/master/BigDiamonds.Rda")
#load(rawConnection(diamondsurl))

# if you manually download the file to your working directory , load the data
getwd()

bd <- load('BigDiamonds.Rda')
head(bd)

```
You can learn how to  scrape data from the web by taking Data Wrangling with MongoDB: Data Manipulation and Retrieval with us.
The code used to obtain the data is available here:
https://github.com/solomonm/diamonds-data

Let's fit the model to this dataset. We will only use GIA certified diamonds. Only at diamonds less than $10000 - because these are sold at most retailers and we care most about 
By trimming most expensive diamonds from the dataset - model less likely to be thrown off by outliers and high variance at the high end of price and carat

## Building a Model Using the Big Diamonds Data Set
'diamondsbig' holds the big dataset - subset this and then build the model

```{r Building a Model Using the Big Diamonds Data Set}
# Your task is to build five linear models like Solomon
# did for the diamonds data set only this
# time you'll use a sample of diamonds from the
# diamondsbig data set.

# Be sure to make use of the same variables
# (logprice, carat, etc.) and model
# names (m1, m2, m3, m4, m5).

# To get the diamondsbig data into RStudio
# on your machine, copy, paste, and run the
# code in the Instructor Notes. There's
# 598,024 diamonds in this data set!

# Since the data set is so large,
# you are going to use a sample of the
# data set to compute the models. You can use
# the entire data set on your machine which
# will produce slightly different coefficients
# and statistics for the models.

# This exercise WILL BE automatically graded.

# You can leave off the code to load in the data.
# We've sampled the data for you.
# You also don't need code to create the table output of the models.
# We'll do that for you and check your model summaries (R^2 values, AIC, etc.)

# Your task is to write the code to create the models.


m1 <- lm(I(log(price)) ~ I(carat^(1/3)), data = diamondsbig[diamondsbig$price < 10000 & diamondsbig$cert=='GIA',])
m2 <- update(m1, ~ . + carat)
m3 <- update(m2, ~ . + cut)
m4 <- update(m3, ~ . + color)
m5 <- update(m4, ~ . + clarity)
mtable(m1, m2, m3, m4, m5)
```
Our models look quite a bit like what we got for the smaller diamonds dataset 
Although our r squared values are a touch weaker


***

## Predictions
### Use the model to make predictions
We need to exponentiate the result of our model since we took the log of price

Example Diamond from BlueNile:
Round 1.00 Very Good I VS1 $5,601

We'll use the full model m5 to predict the value of this diamond

```{r}
#Be sure you’ve loaded the library memisc and have m5 saved as an object in your workspace.
#data.frame creates data frames, tightly coupled collections of variables 
# predict function - refer R documentation - takes the model, df with variables with which it should predict, interval and confidence level

thisDiamond = data.frame(carat = 1.00, cut = "V.Good",
                         color = "I", clarity="VS1")
modelEstimate = predict(m5, newdata = thisDiamond,
                        interval="prediction", level = .95)
exp(modelEstimate)
```

### Evaluate how well the model predicts the BlueNile diamond's price. Think about the fitted point estimate as well as the 95% CI.


The upper and lower bounds are for a 95% CI. Note, because this is a linear model predict is just multiplying each model coefficient by each value in our data.

It turns out that this diamond is a touch pricier than the expected value under the full model, though it is by no means outside the 95% CI
Blue Nile has a good reputation than diamondse.info from where this data set was taken
Though this model can give you a sense of whether this diamond deal is a rip off, against diamondse.info, diamondse.info shouldn't be regarded as the universal source of truth about whether the price is reasonable

Nonetheless, to have the expected price at diamondse.info with a 95% interval is a  lot more information on diamond prices compared to what we had when we started

The prediction interval here may be slightly conservative, as the model errors are heteroskedastic over carat (and hence price) even after our log and cube-root transformations.

See the output of the following code.

```{r}
dat = data.frame(m4$model, m4$residuals)

with(dat, sd(m4.residuals))

with(subset(dat, carat > .9 & carat < 1.1), sd(m4.residuals))

dat$resid <- as.numeric(dat$m4.residuals)
ggplot(aes(y = resid, x = round(carat, 2)), data = dat) +
  geom_line(stat = "summary", fun.y = sd)
```
How could we do better? If we care most about diamonds with carat weights between 0.50 and 1.50, we might restrict the data we use to fit our model to diamonds that are that size - we have enough data.

***

## Final Thoughts
Even though we predict price as f(4c's) one should not conclude that it is irrelevant where you buy the diamond

You obviously pay more for the same diamond at Tiffany's compared to Costco

A model like this gives you a sense of whether you are overpaying 

Data and models are never infallible - you can still get taken even when equipped with this kind of analysis. No substitute for establishing a personal connection and lasting relationship with a jeweler you can trust.

***

Click **KnitHTML** to see all of your hard work and to have an html
page of this lesson, your answers, and your notes!

